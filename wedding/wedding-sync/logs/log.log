[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.plugins]- [Mother Superior] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:00:26 [org.elasticsearch.plugins]- [Mother Superior] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:00:26 [org.elasticsearch.threadpool]- [Mother Superior] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.transport.netty]- [Mother Superior] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.client.transport]- [Mother Superior] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.client.transport]- [Mother Superior] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Mother Superior][management][T#1]]-2014-12-16 21:00:27 [org.elasticsearch.client.transport]- [Mother Superior] failed to connect to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]], ignoring...
org.elasticsearch.transport.ConnectTransportException: [][inet[/127.0.0.1:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannelsLight(NettyTransport.java:698)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:658)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNodeLight(NettyTransport.java:625)
	at org.elasticsearch.transport.TransportService.connectToNodeLight(TransportService.java:153)
	at org.elasticsearch.client.transport.TransportClientNodesService$SniffNodesSampler$1.run(TransportClientNodesService.java:407)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9300
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	... 3 more
[DEBUG]-[main]-2014-12-16 21:00:27 [org.elasticsearch.client.transport]- [Mother Superior] failed to connect to discovered node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
org.elasticsearch.transport.ConnectTransportException: [][inet[/127.0.0.1:9300]] connect_timeout[30s]
	at org.elasticsearch.transport.netty.NettyTransport.connectToChannels(NettyTransport.java:733)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:662)
	at org.elasticsearch.transport.netty.NettyTransport.connectToNode(NettyTransport.java:630)
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:149)
	at org.elasticsearch.client.transport.TransportClientNodesService$NodeSampler.validateNewNodes(TransportClientNodesService.java:299)
	at org.elasticsearch.client.transport.TransportClientNodesService$SniffNodesSampler.doSample(TransportClientNodesService.java:472)
	at org.elasticsearch.client.transport.TransportClientNodesService$NodeSampler.sample(TransportClientNodesService.java:283)
	at org.elasticsearch.client.transport.TransportClientNodesService.addTransportAddresses(TransportClientNodesService.java:166)
	at org.elasticsearch.client.transport.TransportClient.addTransportAddress(TransportClient.java:238)
	at org.springframework.data.elasticsearch.client.TransportClientFactoryBean.buildClient(TransportClientFactoryBean.java:97)
	at org.springframework.data.elasticsearch.client.TransportClientFactoryBean.afterPropertiesSet(TransportClientFactoryBean.java:85)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1613)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1550)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:328)
	at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)
	at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:646)
	at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1115)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1018)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1021)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:964)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:862)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:481)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:290)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1186)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1021)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:964)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:862)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:481)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:290)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1186)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1021)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:964)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:862)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:481)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:290)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1186)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)
	at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:302)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:298)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:706)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:762)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)
	at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)
	at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)
	at com.wedding.sync.factory.ApplicationContextFactory.<clinit>(ApplicationContextFactory.java:11)
	at com.wedding.sync.Bootstrap.main(Bootstrap.java:22)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9300
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)
	at org.elasticsearch.common.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.plugins]- [Melody Guthrie] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:02:00 [org.elasticsearch.plugins]- [Melody Guthrie] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.threadpool]- [Melody Guthrie] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.transport.netty]- [Melody Guthrie] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.client.transport]- [Melody Guthrie] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.client.transport]- [Melody Guthrie] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Melody Guthrie][management][T#1]]-2014-12-16 21:02:00 [org.elasticsearch.transport.netty]- [Melody Guthrie] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:02:00 [org.elasticsearch.transport.netty]- [Melody Guthrie] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:02:01 [org.elasticsearch.transport.netty]- [Melody Guthrie] disconnected from [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:02:01 [org.elasticsearch.transport.netty]- [Melody Guthrie] disconnected from [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.plugins]- [Tarantula] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:05:04 [org.elasticsearch.plugins]- [Tarantula] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.threadpool]- [Tarantula] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.transport.netty]- [Tarantula] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.client.transport]- [Tarantula] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:05:04 [org.elasticsearch.client.transport]- [Tarantula] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Tarantula][management][T#1]]-2014-12-16 21:05:04 [org.elasticsearch.transport.netty]- [Tarantula] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:05:05 [org.elasticsearch.transport.netty]- [Tarantula] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:05:05 [org.elasticsearch.transport.netty]- [Tarantula] disconnected from [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:05:05 [org.elasticsearch.transport.netty]- [Tarantula] disconnected from [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.plugins]- [Umbo] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:06:01 [org.elasticsearch.plugins]- [Umbo] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.threadpool]- [Umbo] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.transport.netty]- [Umbo] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.client.transport]- [Umbo] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.client.transport]- [Umbo] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Umbo][management][T#1]]-2014-12-16 21:06:01 [org.elasticsearch.transport.netty]- [Umbo] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:06:01 [org.elasticsearch.transport.netty]- [Umbo] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:06:02 [org.elasticsearch.transport.netty]- [Umbo] disconnected from [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:06:02 [org.elasticsearch.transport.netty]- [Umbo] disconnected from [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:07:04 [org.elasticsearch.plugins]- [Dusk] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:07:04 [org.elasticsearch.plugins]- [Dusk] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:07:04 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.threadpool]- [Dusk] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.transport.netty]- [Dusk] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.client.transport]- [Dusk] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.client.transport]- [Dusk] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Dusk][management][T#1]]-2014-12-16 21:07:05 [org.elasticsearch.transport.netty]- [Dusk] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:07:05 [org.elasticsearch.transport.netty]- [Dusk] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.plugins]- [Timeshadow] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:08:31 [org.elasticsearch.plugins]- [Timeshadow] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.threadpool]- [Timeshadow] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.transport.netty]- [Timeshadow] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.client.transport]- [Timeshadow] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.client.transport]- [Timeshadow] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Timeshadow][management][T#1]]-2014-12-16 21:08:31 [org.elasticsearch.transport.netty]- [Timeshadow] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:08:31 [org.elasticsearch.transport.netty]- [Timeshadow] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:09:30 [org.elasticsearch.plugins]- [Domo] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:09:30 [org.elasticsearch.plugins]- [Domo] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:09:30 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.threadpool]- [Domo] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.transport.netty]- [Domo] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.client.transport]- [Domo] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.client.transport]- [Domo] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Domo][management][T#1]]-2014-12-16 21:09:31 [org.elasticsearch.transport.netty]- [Domo] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:09:31 [org.elasticsearch.transport.netty]- [Domo] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.plugins]- [The Wink] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:13:00 [org.elasticsearch.plugins]- [The Wink] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.threadpool]- [The Wink] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.transport.netty]- [The Wink] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.client.transport]- [The Wink] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:13:00 [org.elasticsearch.client.transport]- [The Wink] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[The Wink][management][T#1]]-2014-12-16 21:13:00 [org.elasticsearch.transport.netty]- [The Wink] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:13:01 [org.elasticsearch.transport.netty]- [The Wink] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
[DEBUG]-[main]-2014-12-16 21:15:29 [org.elasticsearch.plugins]- [Ozymandias] [/Users/rkzhang/Documents/widding_workspace/wedding/wedding-sync/plugins] directory does not exist.
[INFO]-[main]-2014-12-16 21:15:29 [org.elasticsearch.plugins]- [Ozymandias] loaded [], sites []
[DEBUG]-[main]-2014-12-16 21:15:29 [org.elasticsearch.common.compress.lzf]- using [VanillaChunkDecoder] decoder
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [generic], type [cached], keep_alive [30s]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [index], type [fixed], size [4], queue_size [200]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [snapshot_data], type [scaling], min [1], size [5], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.threadpool]- [Ozymandias] creating thread_pool [bench], type [scaling], min [1], size [2], keep_alive [5m]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.common.netty]- using gathering [true]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.transport.netty]- [Ozymandias] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/3/6/1/1], receive_predictor[512kb->512kb]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.client.transport]- [Ozymandias] node_sampler_interval[5s]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Using select timeout of 500
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.netty.channel.socket.nio.SelectorUtil]- Epoll-bug workaround enabled = false
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.client.transport]- [Ozymandias] adding address [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[elasticsearch[Ozymandias][management][T#1]]-2014-12-16 21:15:30 [org.elasticsearch.transport.netty]- [Ozymandias] connected to node [[#transport#-1][192.168.0.102][inet[/127.0.0.1:9300]]]
[DEBUG]-[main]-2014-12-16 21:15:30 [org.elasticsearch.transport.netty]- [Ozymandias] connected to node [[Star Stalker][DfHiYsuDS4C3s2Ct5L2A4w][192.168.0.102][inet[/192.168.0.102:9300]]]
